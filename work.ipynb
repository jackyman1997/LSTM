{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchmetrics\n",
    "import typing\n",
    "from matplotlib import pyplot as plt\n",
    "from math import isclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_csv_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data = get_csv_data(folder_path=\"./raw_data\")\n",
    "YEAR = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data[:-1]\n",
    "target_data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip\n",
    "features = []\n",
    "targets = []\n",
    "for (feature, target) in zip(input_data, target_data): \n",
    "    features.append(feature.T)\n",
    "    targets.append(target.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np = []\n",
    "targets_np = []\n",
    "\n",
    "for (feature, target) in zip(features, targets):\n",
    "    # feature.drop(\"Date\", axis=0, inplace=True)\n",
    "    # feature.drop(\"Time\", axis=0, inplace=True)\n",
    "    # feature.drop(\"Vol\", axis=0, inplace=True)\n",
    "    # feature.drop(\"Turn\", axis=0, inplace=True)\n",
    "    feature = feature.loc[\"C\"]\n",
    "    target = target.loc[\"C\"]\n",
    "\n",
    "    # feature = (feature - feature.mean())/feature.std()\n",
    "    # target = (target - target.mean())/target.std()\n",
    "\n",
    "    features_np.append(feature.to_numpy(dtype=np.float32).reshape(1, len(feature)))\n",
    "    targets_np.append(target.to_numpy(dtype=np.float32).reshape(1, len(target)))\n",
    "\n",
    "features_np = np.array(features_np)\n",
    "targets_np = np.array(targets_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 377)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_np[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "class StockData(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, features, targets):\n",
    "        self.targets = torch.tensor(targets)  # cast targets to tensor\n",
    "        self.features = torch.tensor(features)  # calculates total count of unique targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.targets[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def split(self, *split_ratio): \n",
    "        '''\n",
    "        returns torch random split object (this instance) \\n\n",
    "        if numbers > 1 are given: check if sum == len, then pass to torch.utils.data.random_split \\n\n",
    "        if numbers < 1 are given: then the sum must == 1, then compute the length og each portion \\n\n",
    "        '''\n",
    "        summed = sum(split_ratio)\n",
    "        if not isclose(summed, 1.0):  # or and abs( 1-sum(split_ratio) ) > 1e-15\n",
    "            if summed != len(self): # check if the sum == len\n",
    "                raise ValueError(\n",
    "                    f\"sum of splitted lengths does not match the data length\\ninstead of the total of {len(self)} or total ratio of 1, {split_ratio} -> {sum(split_ratio)} were given\")  \n",
    "            self.sizes = split_ratio\n",
    "        else:  # if sum == 1\n",
    "            self.sizes = [ int( ratio*len(self) ) for ratio in split_ratio[:-1] ]  # leave one out, the left will be the last term, so that dun need to deal with the rounding problem \n",
    "            self.sizes.append(len(self) - sum(self.sizes))  # add the rest instead of the length*ratio, for the last term\n",
    "        return torch.utils.data.random_split(self, self.sizes)\n",
    "\n",
    "    def dataloader(self, *args, **kwargs: typing.Any):\n",
    "        return torch.utils.data.DataLoader(self, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_len, self.n_features = seq_len, n_features\n",
    "        self.embedding_dim, self.hidden_dim = embedding_dim, 2*embedding_dim\n",
    "\n",
    "        self.rnn = torch.nn.LSTM(\n",
    "            input_size=self.n_features, \n",
    "            hidden_size=self.embedding_dim, \n",
    "            batch_first=True, \n",
    "            num_layers=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #The input x is fed into the encoder. The code h is then fed into the decoder.\n",
    "        # x = x.reshape(\n",
    "        #     (1, self.seq_len, self.n_features)\n",
    "        # )\n",
    "        x, (hidden_n, cell_n) = self.rnn(x)\n",
    "        return hidden_n.reshape((1, self.embedding_dim))\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, seq_len, input_dim=1, output_dim=377):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_len, self.input_dim = seq_len, input_dim\n",
    "        self.hidden_dim, self.output_dim = 2*input_dim, output_dim\n",
    "\n",
    "        self.rnn = torch.nn.LSTM(\n",
    "            input_size=self.input_dim, \n",
    "            hidden_size=self.hidden_dim, \n",
    "            batch_first=True, \n",
    "            num_layers=1,\n",
    "            dropout=0\n",
    "        )\n",
    "\n",
    "        self.dense_layer = torch.nn.Sequential(\n",
    "            # torch.nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            # torch.nn.ReLU(), \n",
    "            torch.nn.Linear(self.hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "        torch.nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #The input x is fed into the encoder. The code h is then fed into the decoder.\n",
    "\n",
    "        x = x.repeat(self.seq_len, 1)\n",
    "\n",
    "        x = x.reshape(\n",
    "            (1, self.seq_len, self.input_dim)\n",
    "        )\n",
    "\n",
    "        x, (hidden_n, cell_n) = self.rnn(x)\n",
    "\n",
    "        x = x.reshape(\n",
    "            (self.seq_len, self.hidden_dim)\n",
    "        )\n",
    "        x = self.dense_layer(x)\n",
    "        return x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self, seq_len=377, output_size=377, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.seq_len, self.output_size = seq_len, output_size\n",
    "        self.enbedding_dim = embedding_dim\n",
    "        #the encoder should have as input size the size of each data sample and as output size the size of the code.\n",
    "        #FFN using ReLu as activation function.\n",
    "        self.encoder = Encoder(self.seq_len, self.output_size, self.enbedding_dim).to(device)\n",
    "        #the decoder hould have as input size the size of the code and as output size the size of the each data sample.\n",
    "        #Another FFN using ReLu as activation function. We want separate neural networks for encoder and decoder.\n",
    "        self.decoder = Decoder(self.seq_len, self.enbedding_dim, self.output_size).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #The input x is fed into the encoder. The code h is then fed into the decoder.\n",
    "        h = self.encoder(x)\n",
    "        r = self.decoder(h)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for .to(device)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load data\n",
    "ready_data = StockData(features_np, targets_np)\n",
    "\n",
    "# split\n",
    "split_size = (0.7, 0.25, 0.05)\n",
    "train_set, test_set, val_set = ready_data.split(*split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train: 628446848.0\n",
      "test: 632247296.0\n",
      "epoch 1\n",
      "train: 630614912.0\n",
      "test: 632243136.0\n",
      "epoch 2\n",
      "train: 631203712.0\n",
      "test: 632239616.0\n",
      "epoch 3\n",
      "train: 631476928.0\n",
      "test: 632236480.0\n",
      "epoch 4\n",
      "train: 631634048.0\n",
      "test: 632233600.0\n",
      "epoch 5\n",
      "train: 631735616.0\n",
      "test: 632230784.0\n",
      "epoch 6\n",
      "train: 631806336.0\n",
      "test: 632227968.0\n",
      "epoch 7\n",
      "train: 631857856.0\n",
      "test: 632225024.0\n",
      "epoch 8\n",
      "train: 631896832.0\n",
      "test: 632221824.0\n",
      "epoch 9\n",
      "train: 631926464.0\n",
      "test: 632217792.0\n",
      "epoch 10\n",
      "train: 631948928.0\n",
      "test: 632212672.0\n",
      "epoch 11\n",
      "train: 631965184.0\n",
      "test: 632205888.0\n",
      "epoch 12\n",
      "train: 631976256.0\n",
      "test: 632197696.0\n",
      "epoch 13\n",
      "train: 631983808.0\n",
      "test: 632188864.0\n",
      "epoch 14\n",
      "train: 631988672.0\n",
      "test: 632179648.0\n",
      "epoch 15\n",
      "train: 631991552.0\n",
      "test: 632170176.0\n",
      "epoch 16\n",
      "train: 631992832.0\n",
      "test: 632160640.0\n",
      "epoch 17\n",
      "train: 631992960.0\n",
      "test: 632151104.0\n",
      "epoch 18\n",
      "train: 631991872.0\n",
      "test: 632141504.0\n",
      "epoch 19\n",
      "train: 631990016.0\n",
      "test: 632132032.0\n",
      "epoch 20\n",
      "train: 631987584.0\n",
      "test: 632122560.0\n",
      "epoch 21\n",
      "train: 631984512.0\n",
      "test: 632113216.0\n",
      "epoch 22\n",
      "train: 631980992.0\n",
      "test: 632103936.0\n",
      "epoch 23\n",
      "train: 631976896.0\n",
      "test: 632094592.0\n",
      "epoch 24\n",
      "train: 631972544.0\n",
      "test: 632085312.0\n",
      "epoch 25\n",
      "train: 631967744.0\n",
      "test: 632076224.0\n",
      "epoch 26\n",
      "train: 631962944.0\n",
      "test: 632067264.0\n",
      "epoch 27\n",
      "train: 631957952.0\n",
      "test: 632058432.0\n",
      "epoch 28\n",
      "train: 631952576.0\n",
      "test: 632049472.0\n",
      "epoch 29\n",
      "train: 631946944.0\n",
      "test: 632040640.0\n",
      "epoch 30\n",
      "train: 631941440.0\n",
      "test: 632031936.0\n",
      "epoch 31\n",
      "train: 631935680.0\n",
      "test: 632023296.0\n",
      "epoch 32\n",
      "train: 631929728.0\n",
      "test: 632014592.0\n",
      "epoch 33\n",
      "train: 631923712.0\n",
      "test: 632006016.0\n",
      "epoch 34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-4b85d1989856>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gg = Autoencoder(377, 377, 1).to(device)\n",
    "\n",
    "# parmas for training loop\n",
    "n_epochs = 10000\n",
    "params = {\n",
    "    \"batch_size\": 1\n",
    "}\n",
    "\n",
    "# loss function, optimiser and metrics \n",
    "loss_func = torch.nn.MSELoss().to(device)\n",
    "optimiser = torch.optim.Adam(gg.parameters(), lr=0.01)\n",
    "metrics = torchmetrics.MeanSquaredError().to(device)\n",
    "\n",
    "for epoch in range(n_epochs): \n",
    "    print(f\"epoch {epoch}\")\n",
    "    # training\n",
    "    for X, y in torch.utils.data.DataLoader(train_set, **params):\n",
    "        # RNN here\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y = y.squeeze(0)\n",
    "        outputs = gg(X)\n",
    "        loss = loss_func(outputs, y)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "        metrics(outputs, y)\n",
    "    met = metrics.compute()\n",
    "    print(f'train: {met}')\n",
    "\n",
    "    # test\n",
    "    for X, y in torch.utils.data.DataLoader(test_set, **params):\n",
    "        # RNN here\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y = y.squeeze(0)\n",
    "        outputs = gg(X)\n",
    "        metrics(outputs, y)\n",
    "    met = metrics.compute()\n",
    "    print(f'test: {met}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation = torch.utils.data.DataLoader(val_set, **params)\n",
    "for i, (X, y) in enumerate(validation): \n",
    "    output = gg(X.to(device))\n",
    "    timesteps = range(torch.flatten(X).shape[0])\n",
    "    X_pred = torch.flatten(output.cpu().detach())\n",
    "    y = torch.flatten(y)\n",
    "    plt.plot(timesteps, X_pred, label=\"predict\")\n",
    "    plt.plot(timesteps, y, label=\"real\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.7281, 7.8880, 8.6725, 8.8649, 8.9098, 8.9209, 8.9239, 8.9248, 8.9251,\n",
       "        8.9252, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253,\n",
       "        8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253, 8.9253])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f5896d0aa3df162656ddf114987f0b25284f674f969bc71da8551ab383a6471"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
